{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "caption.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNY3t2AyVVVNv7qORSfzaBY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/John-p-v1999/Sonnet-generator-final/blob/main/caption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2GPl1ClH5YU"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "########################################################################\n",
        "\n",
        "\n",
        "def cache(cache_path, fn, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Cache-wrapper for a function or class. If the cache-file exists\n",
        "    then the data is reloaded and returned, otherwise the function\n",
        "    is called and the result is saved to cache. The fn-argument can\n",
        "    also be a class instead, in which case an object-instance is\n",
        "    created and saved to the cache-file.\n",
        "    :param cache_path:\n",
        "        File-path for the cache-file.\n",
        "    :param fn:\n",
        "        Function or class to be called.\n",
        "    :param args:\n",
        "        Arguments to the function or class-init.\n",
        "    :param kwargs:\n",
        "        Keyword arguments to the function or class-init.\n",
        "    :return:\n",
        "        The result of calling the function or creating the object-instance.\n",
        "    \"\"\"\n",
        "\n",
        "    # If the cache-file exists.\n",
        "    if os.path.exists(cache_path):\n",
        "        # Load the cached data from the file.\n",
        "        with open(cache_path, mode='rb') as file:\n",
        "            obj = pickle.load(file)\n",
        "\n",
        "        print(\"- Data loaded from cache-file: \" + cache_path)\n",
        "    else:\n",
        "        # The cache-file does not exist.\n",
        "\n",
        "        # Call the function / class-init with the supplied arguments.\n",
        "        obj = fn(*args, **kwargs)\n",
        "\n",
        "        # Save the data to a cache-file.\n",
        "        with open(cache_path, mode='wb') as file:\n",
        "            pickle.dump(obj, file)\n",
        "\n",
        "        print(\"- Data saved to cache-file: \" + cache_path)\n",
        "\n",
        "    return obj\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-v1mlWxGRP8",
        "outputId": "e5f91a3a-736e-4bbf-e0de-03522de306c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "print(keras.__version__)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znEAoJSUIA3d"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "########################################################################\n",
        "\n",
        "# Directory where you want to download and save the data-set.\n",
        "# Set this before you start calling any of the functions below.\n",
        "# Use the function set_data_dir() to also update train_dir and val_dir.\n",
        "data_dir = \"/content/gdrive/My Drive/coco/\"\n",
        "\n",
        "# Sub-directories for the training- and validation-sets.\n",
        "\n",
        "val_dir = \"/content/gdrive/My Drive/coco/val2014/\"\n",
        "train_dir=\"/content/gdrive/My Drive/coco/train2014/\"\n",
        "\n",
        "# Base-URL for the data-sets on the internet.\n",
        "data_url = \"http://images.cocodataset.org/\"\n",
        "\n",
        "\n",
        "########################################################################\n",
        "# Private helper-functions.\n",
        "\n",
        "def _load_records(train=False):\n",
        "    \"\"\"\n",
        "    Load the image-filenames and captions\n",
        "    for either the training-set or the validation-set.\n",
        "    \"\"\"\n",
        "\n",
        "    if train:\n",
        "        # Training-set.\n",
        "        filename = \"captions_train2014.json\"\n",
        "    else:\n",
        "        # Validation-set.\n",
        "        filename = \"captions_val2014.json\"\n",
        "\n",
        "    # Full path for the data-file.\n",
        "    path = os.path.join(data_dir, \"annotations\", filename)\n",
        "\n",
        "    # Load the file.\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data_raw = json.load(file)\n",
        "\n",
        "    # Convenience variables.\n",
        "    images = data_raw['images']\n",
        "    annotations = data_raw['annotations']\n",
        "\n",
        "    # Initialize the dict for holding our data.\n",
        "    # The lookup-key is the image-id.\n",
        "    records = dict()\n",
        "\n",
        "    # Collect all the filenames for the images.\n",
        "    for image in images:\n",
        "        # Get the id and filename for this image.\n",
        "        image_id = image['id']\n",
        "        filename = image['file_name']\n",
        "\n",
        "        # Initialize a new data-record.\n",
        "        record = dict()\n",
        "\n",
        "        # Set the image-filename in the data-record.\n",
        "        record['filename'] = filename\n",
        "\n",
        "        # Initialize an empty list of image-captions\n",
        "        # which will be filled further below.\n",
        "        record['captions'] = list()\n",
        "\n",
        "        # Save the record using the the image-id as the lookup-key.\n",
        "        records[image_id] = record\n",
        "\n",
        "    # Collect all the captions for the images.\n",
        "    for ann in annotations:\n",
        "        # Get the id and caption for an image.\n",
        "        image_id = ann['image_id']\n",
        "        caption = ann['caption']\n",
        "\n",
        "        # Lookup the data-record for this image-id.\n",
        "        # This data-record should already exist from the loop above.\n",
        "        record = records[image_id]\n",
        "\n",
        "        # Append the current caption to the list of captions in the\n",
        "        # data-record that was initialized in the loop above.\n",
        "        record['captions'].append(caption)\n",
        "\n",
        "    # Convert the records-dict to a list of tuples.\n",
        "    records_list = [(key, record['filename'], record['captions'])\n",
        "                    for key, record in sorted(records.items())]\n",
        "\n",
        "    # Convert the list of tuples to separate tuples with the data.\n",
        "    ids, filenames, captions = zip(*records_list)\n",
        "\n",
        "    return ids, filenames, captions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_records(train=False):\n",
        "    \"\"\"\n",
        "    Load the data-records for the data-set. This returns the image ids,\n",
        "    filenames and text-captions for either the training-set or validation-set.\n",
        "    \n",
        "    This wraps _load_records() above with a cache, so if the cache-file already\n",
        "    exists then it is loaded instead of processing the original data-file.\n",
        "    \n",
        "    :param train:\n",
        "        Bool whether to load the training-set (True) or validation-set (False).\n",
        "    :return: \n",
        "        ids, filenames, captions for the images in the data-set.\n",
        "    \"\"\"\n",
        "\n",
        "    if train:\n",
        "        # Cache-file for the training-set data.\n",
        "        cache_filename = \"records_train.pkl\"\n",
        "    else:\n",
        "        # Cache-file for the validation-set data.\n",
        "        cache_filename = \"records_val.pkl\"\n",
        "\n",
        "    # Path for the cache-file.\n",
        "    cache_path = os.path.join(data_dir, cache_filename)\n",
        "\n",
        "    # If the data-records already exist in a cache-file then load it,\n",
        "    # otherwise call the _load_records() function and save its\n",
        "    # return-values to the cache-file so it can be loaded the next time.\n",
        "    records = cache(cache_path=cache_path,\n",
        "                    fn=_load_records,\n",
        "                    train=train)\n",
        "\n",
        "    return records"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVFp8ix4IJPn",
        "outputId": "ce3f22d5-1180-426f-ebe0-43592ac4052a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjpJtJzPEXab"
      },
      "source": [
        "listing the names of images in the directory\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnUKzQPSIM5D"
      },
      "source": [
        "name=os.listdir('/content/gdrive/My Drive/coco/val2014')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0OpXKikIX5r",
        "outputId": "e92edcd9-f7e3-4d09-d10b-54d164e552c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_,filename_train,caption_train=load_records(train=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- Data loaded from cache-file: /content/gdrive/My Drive/coco/records_val.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STiPBe0BIamH"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GMUITOgEfZm"
      },
      "source": [
        "Loading the preprocessed images by the VGG16 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL4D_wiPIckG",
        "outputId": "00765b69-4665-478d-aeb6-b38462cc43ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open(os.path.join(data_dir, \"transfer_values_true.pickle\"), mode='rb') as file:\n",
        "            transfer_values_val = pickle.load(file)\n",
        "transfer_values_val[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.   , 0.   , 1.619, ..., 0.   , 0.   , 0.658], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk65PgrDEml4"
      },
      "source": [
        "loading the captions and tokenizer files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9MSSdSqIw2J"
      },
      "source": [
        "with open(os.path.join(data_dir, \"caption_sos.pickle\"), mode='rb') as file:\n",
        "            captions = pickle.load(file)\n",
        "with open(os.path.join(data_dir, \"tokenizer.pickle\"), mode='rb') as file:\n",
        "            tokeniser = pickle.load(file)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbC3GE2oJfkA"
      },
      "source": [
        "sequence_final=[]\n",
        "for ele in captions:\n",
        "  sequence_inter=tokeniser.texts_to_sequences(ele)\n",
        "  sequence_final.append(sequence_inter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srC76nAGEJrt"
      },
      "source": [
        "preparing the captions and preprocessed images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KIjsXQ_I8RX"
      },
      "source": [
        "def get_random_caption_tokens(idx):\n",
        "  result=[]\n",
        "  for i in idx:\n",
        "    j=np.random.choice(len(sequence_final[i]))\n",
        "    tokens=sequence_final[i][j]\n",
        "    result.append(tokens)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPGSRJl8I-sk"
      },
      "source": [
        "def batch_generator(batch_size):\n",
        "  while True:\n",
        "    idx=np.random.randint(len(name),size=batch_size)\n",
        "    transfer_values =  transfer_values_val[idx]\n",
        "    tokens = get_random_caption_tokens(idx)\n",
        "    num_tokens = [len(t) for t in tokens]\n",
        "    max_tokens=np.max(num_tokens)\n",
        "    tokens_padded = pad_sequences(tokens,maxlen=max_tokens, padding='post',truncating='post')\n",
        "    decoder_input_data = tokens_padded[:, 0:-1]\n",
        "    decoder_output_data = tokens_padded[:,1:]\n",
        "    x_data = \\\n",
        "    {\n",
        "        'decoders_input':decoder_input_data,\n",
        "        'transfer_values_input':transfer_values\n",
        "    }\n",
        "    y_data = \\\n",
        "    {\n",
        "        'decoders_op':decoder_output_data\n",
        "    }\n",
        "    yield (x_data, y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lreCOJH-JA1-"
      },
      "source": [
        "batch_size = 384\n",
        "generator = batch_generator(batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gS6HTvfJDWB"
      },
      "source": [
        "steps_per_epoch = 1541\n",
        "num_words=len(tokeniser.word_index)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj-gkSCkJFRA",
        "outputId": "d86ee7ff-b2ce-4266-b6ae-642fb0f6b70b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "transfer_values_input = keras.layers.Input(shape=(4096,),\n",
        "                              name='transfer_values_input')\n",
        "\n",
        "decoder_transfer_map = keras.layers.Dense(512,\n",
        "                             activation='tanh',\n",
        "                             name='decoder_transfer_map')\n",
        "\n",
        "decoders_input = keras.layers.Input(shape=(None, ), name='decoders_input')\n",
        "decoder_embedding = keras.layers.Embedding(input_dim=num_words+1,\n",
        "                              output_dim=128,\n",
        "                              name='decoder_embedding')\n",
        "\n",
        "decoder_LSTM1 = keras.layers.GRU(512, name='decoder_gru1',\n",
        "                   return_sequences=True)\n",
        "decoder_LSTM2 = keras.layers.GRU(512, name='decoder_gru2',\n",
        "                   return_sequences=True)\n",
        "decoder_LSTM3 = keras.layers.GRU(512, name='decoder_gru3',\n",
        "                   return_sequences=True)\n",
        "\n",
        "decoder_dense=keras.layers.Dense(num_words+1,activation='softmax',name='decoders_op')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5093a12c8d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdecoders_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'decoders_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m decoder_embedding = keras.layers.Embedding(input_dim=num_words+1,\n\u001b[0m\u001b[1;32m     10\u001b[0m                               \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                               name='decoder_embedding')\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_words' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISH8RyB-JJN5"
      },
      "source": [
        "def connect_decoder(transfer_values_input):\n",
        "    \n",
        "    initial_state = decoder_transfer_map(transfer_values_input)\n",
        "    \n",
        "\n",
        "    # Start the decoder-network with its input-layer.\n",
        "    net = decoders_input\n",
        "    \n",
        "    # Connect the embedding-layer.\n",
        "    net = decoder_embedding(net)\n",
        "    \n",
        "    # Connect all the GRU layers.\n",
        "    net = decoder_LSTM1(net, initial_state=initial_state)\n",
        "    net = decoder_LSTM2(net, initial_state=initial_state)\n",
        "    net = decoder_LSTM3(net, initial_state=initial_state)\n",
        "\n",
        "    # Connect the final dense layer that converts to\n",
        "    # one-hot encoded arrays.\n",
        "    decoders_output = decoder_dense(net)\n",
        "    \n",
        "    return decoders_output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xc5RZ8JL5a"
      },
      "source": [
        "decoders_output = connect_decoder(transfer_values_input)\n",
        "\n",
        "decoder_model = keras.Model(inputs=[transfer_values_input, decoders_input],\n",
        "                      outputs=[decoders_output])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdi6VjykJOVv"
      },
      "source": [
        "decoder_model.compile(optimizer=keras.optimizers.RMSprop(lr=1e-3),\n",
        "                      loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa_4JlH-fB_o",
        "outputId": "55e1e7ec-968a-46df-f7e0-bc753ca70d22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "decoder_model.fit(x=generator,\n",
        "                  steps_per_epoch=steps_per_epoch,\n",
        "                  epochs=5)\n",
        "decoder_model.save_weights('/content/gdrive/My Drive/coco/decoder_model_weights_VGG16_finese',overwrite=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1541/1541 [==============================] - 129s 84ms/step - loss: 1.5885\n",
            "Epoch 2/5\n",
            "1541/1541 [==============================] - 129s 84ms/step - loss: 1.1677\n",
            "Epoch 3/5\n",
            "1541/1541 [==============================] - 129s 84ms/step - loss: 1.0312\n",
            "Epoch 4/5\n",
            "1541/1541 [==============================] - 128s 83ms/step - loss: 0.9253\n",
            "Epoch 5/5\n",
            "1541/1541 [==============================] - 128s 83ms/step - loss: 0.8305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqw4_4ub5rw2",
        "outputId": "24002233-d708-4b1e-dfec-324b235b4a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_model.save('/content/gdrive/My Drive/coco/decoder_model')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/coco/decoder_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfoffvVibem2"
      },
      "source": [
        "from tensorflow import keras\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqKUGWzoJ17v",
        "outputId": "16c160ea-ff46-4bce-c7dc-4365f3e74381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_model.load_weights('/content/gdrive/My Drive/coco/decoder_model_weights_VGG16_finese')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd65d7cdeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJRSTsC4J93B",
        "outputId": "0b266619-b49c-48c3-e063-cc14f93ff2f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        }
      },
      "source": [
        "from keras.applications import VGG16\n",
        "base_model=VGG16(weights='imagenet',include_top=True)\n",
        "for layers in base_model.layers:\n",
        "  layers.trainable=False\n",
        "last_layer=base_model.layers[-3]\n",
        "last_output=last_layer.output\n",
        "\n",
        "img_model=keras.Model(base_model.input,last_output)\n",
        "img_model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "=================================================================\n",
            "Total params: 117,479,232\n",
            "Trainable params: 0\n",
            "Non-trainable params: 117,479,232\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABgeu9y2DyTB"
      },
      "source": [
        "TESTING PHASE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciagDIm924Qr"
      },
      "source": [
        "img_model.save('/content/gdrive/My Drive/coco/VGG16foruse.h5')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyWWPpFeJ_8t",
        "outputId": "018a713b-8186-47b3-b1ea-b5c9830fa631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "img=Image.open('/content/gdrive/My Drive/coco/val2014/COCO_val2014_000000000536.jpg')\n",
        " \n",
        "img=img.resize(size=(224,224), resample=Image.LANCZOS)\n",
        "image=np.array(img)\n",
        "img=image/255.0\n",
        "image_batch = np.expand_dims(img, axis=0)\n",
        "print(image_batch.shape)\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 224, 224, 3)\n",
            "(224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd2DKEw4KA-F"
      },
      "source": [
        "transfered_values = img_model.predict(image_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iaeqgz9mKC3g",
        "outputId": "fe36ea6c-0a34-44ef-ee14-47ea30280d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "start_word=tokeniser.word_index['sos']\n",
        "end_word=tokeniser.word_index['eos']\n",
        "corpus_index=tokeniser.word_index\n",
        "corpus_index={value:key for key,value in corpus_index.items()}\n",
        "reverse_corpus_index={value:key for key,value in corpus_index.items()}\n",
        "reverse_corpus_index['horse']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr-FAXloKO_8"
      },
      "source": [
        "def sample(preds,temperature=1.0):\n",
        "  preds =np.asarray(preds).astype('float64')\n",
        "  preds=np.log(preds)/temperature\n",
        "  exp_preds=np.exp(preds)\n",
        "  preds=exp_preds/np.sum(exp_preds)\n",
        "  \n",
        "  \n",
        "  '''preds=preds.reshape(preds.shape[1])'''\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKS_hxnwKUGJ"
      },
      "source": [
        "decode_input=np.zeros(shape=(1,10),dtype=np.int)\n",
        "\n",
        "curr_token=start_word\n",
        "count_tokens=0\n",
        "max_token=10\n",
        "output_text = ''\n",
        "while curr_token!=end_word and count_tokens<max_token:\n",
        "  decode_input[0,count_tokens]=curr_token\n",
        "  x_data={\n",
        "      'transfer_values_input': transfered_values,\n",
        "      'decoders_input': decode_input\n",
        "  }\n",
        "  decode_output = decoder_model.predict(x_data)\n",
        "  token_output=decode_output[0,count_tokens,:]\n",
        "  pred=np.argmax(token_output)\n",
        "  \n",
        "  curr_token=pred\n",
        "  sampled_word = corpus_index[pred]\n",
        "  output_text += \" \" + sampled_word\n",
        "  count_tokens += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZhIrgN6bCUN",
        "outputId": "4ed2b4c4-cd30-417e-c378-332a741b8e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "output_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' a man is holding a box of pizza in a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vofpC2SKefW8"
      },
      "source": [
        "transfer_values_input = keras.layers.Input(shape=(4096,),\n",
        "                              name='transfer_values_input')\n",
        "\n",
        "decoder_transfer_map = keras.layers.Dense(512,\n",
        "                             activation='tanh',\n",
        "                             name='decoder_transfer_map')\n",
        "decoder_transfer_map_averaged=keras.layers.GlobalAveragePooling1D()\n",
        "decoders_input = keras.layers.Input(shape=(None, ), name='decoders_input')\n",
        "decoder_embedding = keras.layers.Embedding(input_dim=num_words+1,\n",
        "                              output_dim=128,\n",
        "                              name='decoder_embedding')\n",
        "\n",
        "decoder_LSTM1 = keras.layers.GRU(512, name='decoder_gru1',\n",
        "                   return_sequences=True)\n",
        "decoder_LSTM2 = keras.layers.GRU(512, name='decoder_gru2',\n",
        "                   return_sequences=True)\n",
        "decoder_LSTM3 = keras.layers.GRU(512, name='decoder_gru3',\n",
        "                   return_sequences=True)\n",
        "\n",
        "decoder_dense=keras.layers.Dense(num_words+1,activation='linear',name='decoders_op')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbkUOw_xeqyA"
      },
      "source": [
        "def connect_decoder(transfer_values_input):\n",
        "    \n",
        "    initial_state = decoder_transfer_map(transfer_values_input)\n",
        "    \n",
        "\n",
        "    # Start the decoder-network with its input-layer.\n",
        "    net = decoders_input\n",
        "    \n",
        "    # Connect the embedding-layer.\n",
        "    net = decoder_embedding(net)\n",
        "    \n",
        "    # Connect all the GRU layers.\n",
        "    net = decoder_LSTM1(net, initial_state=initial_state)\n",
        "    net = decoder_LSTM2(net, initial_state=initial_state)\n",
        "    net = decoder_LSTM3(net, initial_state=initial_state)\n",
        "\n",
        "    # Connect the final dense layer that converts to\n",
        "    # one-hot encoded arrays.\n",
        "    decoders_output = decoder_dense(net)\n",
        "    \n",
        "    return decoders_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VFtCVwVezo2"
      },
      "source": [
        "decoders_output = connect_decoder(transfer_values_input)\n",
        "\n",
        "decoder_model = keras.Model(inputs=[transfer_values_input, decoders_input],\n",
        "                      outputs=[decoders_output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uFJqVe3e2S6"
      },
      "source": [
        "import tensorflow as tf\n",
        "def sparse_crossentropy(y_true, y_pred):\n",
        "  loss=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
        "  loss_mean = tf.reduce_mean(loss)\n",
        "  return loss_mean "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex4rz1n1e5Gk"
      },
      "source": [
        "decoder_target= tf.keras.backend.placeholder(dtype='int32', shape=(None,None))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzqFB46oe-70"
      },
      "source": [
        "decoder_model.compile(optimizer=keras.optimizers.RMSprop(lr=1e-3),\n",
        "                      loss=sparse_crossentropy,\n",
        "                      \n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}